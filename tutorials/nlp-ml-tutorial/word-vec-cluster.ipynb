{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pre-Trained Word Vectors for Clustering Text Documents\n",
    "\n",
    "A common practice for clustering word documents involves using Tfidf vectorization along with KMeans. This of course is simple and powerful - but essentially has the limits of known bag of words - which in case of sparsity of ground truth can have poor results. Now with pre-trained word vectors, once can theoretically overcome the some of this limitations as rather than clustering on ground truth embodied in just the training set, one can gain the power of a much larger word space.\n",
    "\n",
    "The following example provides an implementation where one can choose to cluster through Tfidf vectorization - or use pre-trained word vectors. One can see that by using pre-trained word vectors, \"Orange is hip\" is correctly clustered with the other similar color based sentences, while \"Cooking is my hobby\" is positioned closer to the food sentences!\n",
    "\n",
    "For more information on word vectors, please see:\n",
    "\n",
    "[Deep Learning, NLP, and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n",
    "\n",
    "[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.utils.extmath import row_norms, squared_norm\n",
    "from sklearn.cluster.k_means_ import _labels_inertia\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_clusters(docs, num_clusters, vector_type=\"spacy\"):    \n",
    "    # create the vectorizer & feature matrix based on that \n",
    "    if vector_type == \"count\":\n",
    "        vectorizer = CountVectorizer()\n",
    "        # Converting todense to use in the PCA reduction for 2D plotting\n",
    "        feature_matrix = vectorizer.fit_transform(docs).todense()\n",
    "    elif vector_type == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        # Converting todense to use in the PCA reduction for 2D plotting\n",
    "        feature_matrix = vectorizer.fit_transform(docs).todense()\n",
    "    elif vector_type == \"spacy\":\n",
    "        # ensure that the model has been downloaded previously\n",
    "        # python -m spacy download en_vectors_glove_md\n",
    "        nlp = spacy.load('en_vectors_glove_md') \n",
    "        feature_matrix = list()\n",
    "        for doc in docs:\n",
    "            feature_matrix.append(nlp(doc).vector)\n",
    "        \n",
    "    km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=20, n_init=10)\n",
    "    cluster_labels = km.fit_predict(feature_matrix)\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        print(cluster_labels[i], doc)\n",
    "    \n",
    "    # now reduce feature matrix to 2 dimensions and plot it\n",
    "    pca = PCA(n_components=2).fit(feature_matrix)       \n",
    "    data2D = pca.transform(feature_matrix)\n",
    "    colors = cm.spectral(cluster_labels.astype(float) / num_clusters)\n",
    "    plt.scatter(data2D[:,0], data2D[:,1], color=colors)\n",
    "     \n",
    "    centers2D = pca.transform(km.cluster_centers_)\n",
    "\n",
    "    plt.hold(True)\n",
    "    plt.scatter(centers2D[:,0], centers2D[:,1], \n",
    "                marker='x', s=200, linewidths=3, c='r')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"The colors are amazing\", \"Japanese food is great\", \n",
    "        \"My favorite color is blue\", \"I love Indian food\", \n",
    "        \"Orange is hip\", \"Cooking is my hobby\"]\n",
    "\n",
    "show_clusters(docs, 2, vector_type=\"spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
